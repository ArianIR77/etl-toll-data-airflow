# ETL Toll Data Pipeline â€“ Apache Airflow

This project is a hands-on lab assignment for building an ETL pipeline using Apache Airflow's BashOperator.

## ðŸ›  Technologies Used
- Apache Airflow
- Bash
- Python (for orchestration)
- CLI / Web UI

## ðŸ“‹ Tasks Performed
- Extract from CSV, TSV, and fixed-width files
- Consolidate and transform data
- Load into a staging area
- Schedule and run DAG using Airflow


## ðŸš€ How to Run
- Copy `ETL_toll_data.py` to your Airflow DAGs folder
- Start Airflow webserver and scheduler
- Trigger DAG from UI or CLI


